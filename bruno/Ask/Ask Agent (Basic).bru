meta {
  name: Ask Agent (Basic)
  type: http
  seq: 1
}

post {
  url: {{base_url}}/api/v1/stream
  body: json
  auth: none
}

headers {
  Content-Type: application/json
}

body:json {
  {
    "query": "Hello. Can you tell me about machine learning",
    "session_id": "optional-uuid-for-conversation"
  }
}

docs {
  Stream agent response via Server-Sent Events (SSE) using default LLM provider and model. Features guardrail validation, document grading, query rewriting, and optional multi-turn conversation memory. Response includes status updates, content tokens, sources, and metadata as separate SSE events.
}
